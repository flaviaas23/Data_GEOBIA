{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://raw.githubusercontent.com/brazil-data-cube/code-gallery/master/img/logo-bdc.png\" align=\"right\" width=\"64\" />\n",
    "\n",
    "# <span style=\"color:#336699\">Image processing on images obtained through STAC</span>\n",
    "<hr style=\"border:2px solid #0077b9;\">\n",
    "\n",
    "<div style=\"text-align: left;\">\n",
    "    <a href=\"https://nbviewer.jupyter.org/github/brazil-data-cube/code-gallery/blob/master/jupyter/Python/stac/stac-image-processing.ipynb\"><img src=\"https://raw.githubusercontent.com/jupyter/design/master/logos/Badges/nbviewer_badge.svg\" align=\"center\"/></a>\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: center;font-size: 90%;\">\n",
    "    Rennan Marujo<sup><a href=\"https://orcid.org/0000-0002-0082-9498\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Gilberto R. Queiroz<sup><a href=\"https://orcid.org/0000-0001-7534-0219\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>, Felipe Menino Carlos<sup><a href=\"https://orcid.org/0000-0002-3334-4315\"><i class=\"fab fa-lg fa-orcid\" style=\"color: #a6ce39\"></i></a></sup>\n",
    "    <br/><br/>\n",
    "    Earth Observation and Geoinformatics Division, National Institute for Space Research (INPE)\n",
    "    <br/>\n",
    "    Avenida dos Astronautas, 1758, Jardim da Granja, São José dos Campos, SP 12227-010, Brazil\n",
    "    <br/><br/>\n",
    "    Contact: <a href=\"mailto:brazildatacube@inpe.br\">brazildatacube@inpe.br</a>\n",
    "    <br/><br/>\n",
    "    Last Update: December 08, 2021\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "\n",
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%;\">\n",
    "<b>Abstract.</b> This Jupyter Notebook describes how to search for CBERS-4 data products in <em>Brazil Data Cube</em>'s catalog through the STAC service. Then it shows how to use Python libraries to perform some image processing. It starts by computing the Normalized Difference Vegetation Index (NDVI) based on the red and near-infrared spectral bands. Next, it demonstrates a threshold analysis based on the computed NDVI. Lastly, it computes the NDVI difference for images from two diffrent dates.\n",
    "</div>\n",
    "\n",
    "<br/>\n",
    "<div style=\"text-align: justify;  margin-left: 25%; margin-right: 25%;font-size: 75%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>For an introduction to the SpatioTemporal Asset Catalog (STAC) with the <em>Brazil Data Cube</em> infrastructure, please, refer to the following Jupyter Notebook:</b>\n",
    "    <div style=\"margin-left: 10px; margin-right: 10px\">\n",
    "    Zaglia, M.; Marujo, R.; Queiroz, G. R.; Carlos, F. M. <a href=\"./stac-introduction.ipynb\" target=\"_blank\">Introduction to the SpatioTemporal Asset Catalog (STAC)</a>.\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://raw.githubusercontent.com/brazil-data-cube/code-gallery/master/img/stac/stac.png?raw=true\" align=\"right\" width=\"66\"/>\n",
    "\n",
    "# STAC Client API\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "For running the examples in this Jupyter Notebook you will need to install the [STAC client for Python](https://github.com/brazil-data-cube/stac.py). To install it from PyPI using `pip`, use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pystac-client==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install rasterio shapely matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to access the funcionalities of the client API, you should import the `pystac_client` package, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pystac_client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that, you can check the installed `pystac_client` package version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pystac_client.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, create a `pystac_client.Client` object attached to the Brazil Data Cube' STAC service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(access_token='change-me')\n",
    "service = pystac_client.Client.open('https://brazildatacube.dpi.inpe.br/stac/', parameters=parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for CBERS-4 Images\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the STAC `search` API to look for images from the data cube named `CB4-16D-2`. This data cube is a temporal composite from CBERS-4/AWFI surface reflectance data. Let's define a search box with the following bounds: $x_{min} = -45.9$, $x_{max} = -45.4$, $y_{min} = -12.9$, $y_{max} = -12.6$. Besides that, the period of interest ranges from August 1st, 2018 to July 31st, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = (-45.9, -12.9, -45.4, -12.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_search = service.search(collections=['CB4-16D-2'],\n",
    "                             bbox=bbox,\n",
    "                             datetime='2018-08-01/2019-07-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pystac_client.item_search.ItemSearch at 0x1117e9550>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above query, should return 24 items for this particular data cube:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_search.matched()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Indices\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectral indices are computed using sensor bands to highlight a certain feature of a target or reduce certain effects. In this context, vegetation indices are spectral indices that enhance characteristics of vegetation, using bands such as Near Infra-red (`NIR`), a region where vegetation shows the most intense reflectance and bands located in red, where the vegetation has the highest absorption of visible sunlight due to the presence in its constitution of the green pigment chlorophyll (Meneses, 2012). The behavior of these spectral bands in some types of targets can be observed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://brazil-data-cube.github.io/_images/spectral-profile.png\" width=\"480\" />\n",
    "<br/>\n",
    "Spectral profile of several targets. Source: modified from Pan et. al (2015).\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating the Normalized Difference Vegetation Index (NDVI)\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The normalized difference vegetation index (NDVI) is calculated using the **Red** and **Near Infrared** (NIR) spectral bands. It assesses whether or not the target being observed contains live green vegetation. It can be calculated through the following equation:\n",
    "\n",
    "$$\n",
    "NDVI = \\frac{(NIR - RED)}{(NIR + RED)}\n",
    "$$\n",
    "\n",
    "<center><b>Equation 1</b> - NDVI.</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to compute the NDVI just with images from the first item:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(item_search.get_items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Item id=CB4-16D_V2_007004_20190728>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item = items[0]\n",
    "item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to know which band is available in an item, one can access its metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'BAND13',\n",
       "  'common_name': 'blue',\n",
       "  'description': 'Band 13 blue',\n",
       "  'min': 0.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': 0.485,\n",
       "  'full_width_half_max': 0.07,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'BAND14',\n",
       "  'common_name': 'green',\n",
       "  'description': 'Band 14 green',\n",
       "  'min': 0.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': 0.555,\n",
       "  'full_width_half_max': 0.07,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'BAND15',\n",
       "  'common_name': 'red',\n",
       "  'description': 'Band 15 red',\n",
       "  'min': 0.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': 0.66,\n",
       "  'full_width_half_max': 0.06,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'BAND16',\n",
       "  'common_name': 'nir',\n",
       "  'description': 'Band 16 nir',\n",
       "  'min': 0.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': 0.83,\n",
       "  'full_width_half_max': 0.12,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'CLEAROB',\n",
       "  'common_name': 'ClearOb',\n",
       "  'description': 'Clear Observation Count',\n",
       "  'min': 1.0,\n",
       "  'max': 255.0,\n",
       "  'nodata': 0.0,\n",
       "  'scale': 1.0,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'uint8'},\n",
       " {'name': 'CMASK',\n",
       "  'common_name': 'quality',\n",
       "  'description': 'Band CMASK cloud',\n",
       "  'min': 0.0,\n",
       "  'max': 255.0,\n",
       "  'nodata': 0.0,\n",
       "  'scale': 1.0,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'uint8'},\n",
       " {'name': 'EVI',\n",
       "  'common_name': 'evi',\n",
       "  'description': 'Enhanced Vegetation Index',\n",
       "  'min': -10000.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'NDVI',\n",
       "  'common_name': 'ndvi',\n",
       "  'description': 'Normalized Difference Vegetation Index',\n",
       "  'min': -10000.0,\n",
       "  'max': 10000.0,\n",
       "  'nodata': -9999.0,\n",
       "  'scale': 0.0001,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'PROVENANCE',\n",
       "  'common_name': 'Provenance',\n",
       "  'description': 'Provenance value day of year',\n",
       "  'min': 1.0,\n",
       "  'max': 366.0,\n",
       "  'nodata': -1.0,\n",
       "  'scale': 1.0,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'int16'},\n",
       " {'name': 'TOTALOB',\n",
       "  'common_name': 'TotalOb',\n",
       "  'description': 'Total Observation Count',\n",
       "  'min': 1.0,\n",
       "  'max': 255.0,\n",
       "  'nodata': 0.0,\n",
       "  'scale': 1.0,\n",
       "  'center_wavelength': None,\n",
       "  'full_width_half_max': None,\n",
       "  'data_type': 'uint8'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(item.properties['eo:bands'], key=lambda band: band['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> As one can see, in the above metadata the Brazil Data Cube already provides the <em>NDVI</em> and <em>EVI</em> alongside with the spectral bands for the data cubes, besides the quality indicators (<em>CLEAROB</em>, <em>PROVENANCE</em>, <em>CMASK</em>, <em>TOTALOB</em>).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see in the above cell, the `BAND15` correspond to the red wavelength and `BAND16` to the near-infrared.\n",
    "\n",
    "We have implemented a basic `read` method that allows to retrieve part of an image according to a rectangle specified in `EPSG:4326`. The next cells reads the `red` and `nir` bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.crs import CRS\n",
    "from rasterio.warp import transform\n",
    "from rasterio.windows import from_bounds\n",
    "\n",
    "def read(uri: str, bbox: list, masked: bool = True, crs: str = None):\n",
    "    \"\"\"Read raster window as numpy.ma.masked_array.\"\"\"\n",
    "    source_crs = CRS.from_string('EPSG:4326')\n",
    "    if crs:\n",
    "        source_crs = CRS.from_string(crs)\n",
    "\n",
    "    # Expects the bounding box has 4 values\n",
    "    w, s, e, n = bbox\n",
    "        \n",
    "    with rasterio.open(uri) as dataset:\n",
    "        transformer = transform(source_crs, dataset.crs, [w, e], [s, n])\n",
    "        window = from_bounds(transformer[0][0], transformer[1][0], \n",
    "                             transformer[0][1], transformer[1][1], dataset.transform)\n",
    "        return dataset.read(1, window=window, masked=masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = read(item.assets['BAND15'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> If there are errors because of your pyproj version, you can run the code below as specified in <a  href=\"https://rasterio.readthedocs.io/en/latest/faq.html#why-can-t-rasterio-find-proj-db-rasterio-from-pypi-versions-1-2-0\" target=\"_blank\">rasterio documentation</a> and try again:\n",
    "\n",
    "       import os\n",
    "       del os.environ['PROJ_LIB']\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir = read(item.assets['BAND16'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the retrieved data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(red, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(nir, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's compute the NDVI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi = (nir - red)/(nir + red)\n",
    "ndvi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Matplotlib to visualize the result array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndvi, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot using other colormaps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(ndvi, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more colormaps check https://matplotlib.org/stable/tutorials/colors/colormaps.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The histogram of a digital image, also known as frequency distribution, is the graphic representation in columns showing the intensity of values and the number of pixels with such intensity and is the basis for several types of digital image processing (Gonzalez & Woods, 2007). Some types of histogram can be observed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"https://brazil-data-cube.github.io/_images/histogram.png\" width=\"480\" />\n",
    "<br/>\n",
    "Four types of images: dark, bright, low contrast and high contrast, and their respective histograms. Source: (Gonzalez & Woods, 2007).\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding images\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digital image Classification is a broad topic and basically consists of assigning labels to targets in a dataset, also called classes. Although many of the classification approaches are complex, there are some simple approaches to solving certain problems, such as thresholding.\n",
    "\n",
    "The idea of assigning a class following a threshold assumes that the data can be separated by a simple \"line\", this can be seen in the next figures in a histogram:\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"https://scikit-image.org/docs/dev/_images/sphx_glr_plot_multiotsu_001.png\" width=\"960\" />\n",
    "<br/>\n",
    "Histogram limiarization example. Source: <a href=\"https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_multiotsu.html\">scikit-image doc</a>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to separate our data into groups according to their NDVI values.\n",
    "But first let's see how the image histogram behaves:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"NDVI Histogram\")\n",
    "plt.hist(ndvi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supposing we can separate the `ndvi` image with threshold, we would assume for this specific case that:\n",
    "* all pixels with values below 0.2 are dark pixels;\n",
    "* all pixels above 0.45 are areas containing a good portion of vegetation.\n",
    "* all pixels with values from 0.2 to 0.45 are areas with few vegetation;\n",
    "\n",
    "We can perform this thresholding by selecting in the ndvi matrix all values belonging to a given range and assigning a common integer value. We assume the following integer values:\n",
    "* `1`: dark pixels;\n",
    "* `2`: vigorous vegetation;\n",
    "* `3`: weak vegetation.\n",
    "\n",
    "Let's first create a copy of the original ndvi matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img = ndvi.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the new copy of the ndvi array and assign the values according to each range of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_img[ndvi < 0.2] = 1 # < 0.2\n",
    "labeled_img[ndvi >= 0.2] = 3 # 0.2 - 0.45\n",
    "labeled_img[ndvi >= 0.45] = 2 # >= 0.45\n",
    "labeled_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's see the `ndvi` image separated into those labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [30, 20] #Change plot size\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ndvi, cmap='gray')\n",
    "ax2.imshow(labeled_img, cmap='brg');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Image Difference\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's suppose we want to compare the NDVI for images from two different dates and same location, for instance to verify the areas where crops have grown and areas that loss vegetation.\n",
    "\n",
    "For this computation we are going to use the NDVI bands provided in the data cube, and we will select two items (with the same location but with different dates) using STAC.\n",
    "\n",
    "The first image comprises pixels from July 28th, 2019 to August 12th, 2019 (`2019-07-28_2019-08-12`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_item = item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_first_image = read(first_item.assets['NDVI'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other selected image comprises pixels from January 01st, 2019 to January 16th, 2019 (`2019-01-01_2019-01-16`) - i.e., six months before the first one selected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_item = items[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_second_image = read(second_item.assets['NDVI'].href, bbox=bbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify;  margin-left: 15%; margin-right: 15%; border-style: solid; border-color: #0077b9; border-width: 1px; padding: 5px;\">\n",
    "    <b>Note:</b> NDVI bands precomputed by BDC ranges from <em>-10000</em> to <em>10000</em>, instead of <em>-1</em> to <em>1</em>, as can be seen in the item metadata. This is due to the lower volume required to store files that use 16-bit integer values rather than 32-bit float.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considering that these images are from an agricultural area and that crops are normally planted near August (first observation), in a six months, previous or after the first observation, it is expected to find crops, which will imply in greater NDVI values (more vigorous vegetation). This will cause NDVI band to present brighter values on these areas. Using the `gray` colormap, high value NDVI pixels will be more similar to white, while low value NDVI pixels will be closer to the black color.\n",
    "Based on that, let's visually compare both NDVI images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(ndvi_first_image, cmap='gray')\n",
    "ax2.imshow(ndvi_second_image, cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we want to see what have grown and what was loss, let's subtract the most recent image from the oldest one and plot it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndvi_diff = ndvi_first_image - ndvi_second_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.imshow(ndvi_diff, cmap='jet');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the the NDVI difference plot, the main changes on pixel values were found in agriculture areas, which was expected due to changes in crops.\n",
    "The blue values indicate negative values, while red values are positive. This means that for the blue areas there was a loss of vegetation, as a decreasing result on the NDVI value, meaning that crops were harvest. Meanwhile, on the red areas, the NDVI value increased as a result of the more vigorous vegetation on the recent date."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "<hr style=\"border:1px solid #0077b9;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Python Client Library for STAC Service](https://pystac-client.readthedocs.io/en/latest/)\n",
    "\n",
    "- [Spatio Temporal Asset Catalog Specification](https://stacspec.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See also the following Jupyter Notebooks\n",
    "<hr style=\"border:1px solid #0077b9;\">\n",
    "\n",
    "* [Introduction to the SpatioTemporal Asset Catalog (STAC)](./stac-introduction.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
